# Pupil Tracker

This project is a high-accuracy computer vision system designed for tracking and analyzing the position of the pupil in video frames. The project leverages modern deep learning techniques and transfer learning to achieve robust and efficient tracking, making it suitable for research, experimentation, and practical applications in eye-tracking and behavioral analysis.

## Project Structure

- `data/` - Contains datasets, including:
  - `lpw/annotations/` - Annotation text files for each video.
  - `lpw/extracted_frames/` - Extracted frames from videos as PNG images.
  - `lpw/videos/` - Raw video files (AVI format).
- `logs/` - Training and validation logs (e.g., TensorBoard events).
- `output_frames/` - Output frames generated by the model or scripts.
- `requirements.txt` - Python dependencies for the project.
- `saved_models/` and `saved_models_v2/` - Saved Keras model files.
- `test_images/` - Test images and videos for inference/testing.
- `test.py` - Script for testing/inference with saved models.
- `train.py` - Script for training models on the dataset.

## Project Description

Vision Tracker is a high-accuracy computer vision system designed for tracking and analyzing the position of the pupil in video frames. The project leverages modern deep learning techniques and transfer learning to achieve robust and efficient tracking, making it suitable for research, experimentation, and practical applications in eye-tracking and behavioral analysis.

### Key Concepts and Techniques

- **Deep Learning & Transfer Learning:**  
  Utilizes TensorFlow and Keras, with MobileNetV2 as a backbone for feature extraction. Transfer learning allows the model to benefit from pre-trained weights on large datasets, improving accuracy and reducing training time.

- **Custom Loss Function (Wing Loss):**  
  Implements the Wing Loss function, which is particularly effective for regression tasks involving keypoint localization, such as pupil tracking. This loss is robust to outliers and helps the model focus on small errors.

- Data Augmentation: Uses the `imgaug` library to perform advanced data augmentation, increasing the diversity of the training data and improving model generalization.

- Efficient Data Handling: Employs custom data generators for efficient loading and augmentation of large video datasets, supporting batch processing and shuffling.

- Experiment Tracking and Logging: Integrates TensorBoard for real-time visualization of training and validation metrics. Optionally supports experiment tracking with Weights & Biases (`wandb`).

- Computer Vision Preprocessing: Uses OpenCV for frame extraction, image processing, and annotation handling.

### Technologies and Libraries

- **TensorFlow / Keras:** Deep learning framework for model building and training.
- **OpenCV:** Computer vision library for image and video processing.
- **imgaug:** Advanced image augmentation for deep learning.
- **scikit-learn:** Utilities for data splitting and preprocessing.
- **NumPy, Pandas:** Data manipulation and analysis.
- **tqdm:** Progress bars for data processing.
- **TensorBoard:** Visualization of training progress.
- **Weights & Biases (optional):** Experiment tracking.
- **scikit-image:** Additional image processing utilities.

## Setup

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd vision-tracker
   ```
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## Usage

- **Training:**
  ```bash
  python train.py
  ```
- **Testing/Inference:**
  ```bash
  python test.py
  ```

## License
 MIT

---
